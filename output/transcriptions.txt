===== BEGIN TRANSCRIPT =====
Video ID: BGSOtfZ-skk
Language: en
Source: auto-generated
Saved At: 2025-08-17T10:33:09.041187
Starting with structured output and prompt engineering. Anyone has prompted a model and you've likely prompted a model to get JSON or CSV output, right? Anyone here asked the model to output JSON, CSV, something like that? Hence, yeah, right? Cool. So, if you done that, you just do it like this. You get the model saying, "Hey, cool. I'll do that for you." And then, uh, you got some JSON. Now, trying to parse this in your code, no, that is quite difficult. you'll have to try and find where the
JSON starts and it's not great. You can tell the model to only output JSON and it will only output JSON 99% of the time. That one% you'll get a crash or an error. So, I I've mentioned this and you know it might sound very obvious to you, but I've talked to so many devs recently that told me they don't use structured output. They just do it by telling the model to only output JSON in the format they want in their prompt, which does work, but there's no validation from the prompting framework.
There's no confirmation. You know, it's just luck. And there will happen cases where your code will not work because the LM will return, sure, I'll do that for you because they're helpful. To get around that, and to be absolutely sure that the output you'll get is JSON in the exact schema that you want, we use structured output. Don't worry about the schema. We'll go into that a little bit later. The whole point you pass um a JSON schema to the model um most models support this even llama 4 GMA
all of them do structured output to get deterministic output because all of our code is deterministic and that's what matters right to get deterministic output to run with our deterministic code. Doing this is quite simple. We put in the uh the structured output model, the schema, we turn it on and the return we'll get is pure JSON in the exact format that we want. And that way we can run it in our code and we can make sure everything works. Really important if you want to render UI as well.
Prompting models quite simple. Going to prompt Gemini. All you need to do is install a GI SDK in any language that you'd like. It exists in pretty much anything. And if it doesn't, you can use the rest API that Google provides. um select the model, give it a prompt, you're good. Now, if you want to pass a schema, I at least when I work in NodeJS, like to uh define them in Typescript because that way I get a little bit of support from the system when I write them. I make sure there's no type
errors. You know, I get linting support during build time and it just makes my life a little bit easier. And we get one huge benefit when we define our schemas uh instead of using structured output. Apart from the uh uh the benefit of actually getting our schema output, the big benefit we get is we can also define exact descriptions for specific properties. So here we say start date that we want exactly in this format. Has anyone here worked with dates in in any kind of coding languages? Did you
enjoy your time or did you >> No. Yes. Everyone hates dates and being, you know, getting some more predictability in there to know, okay, I'll get year, month, date, hour, whatever, time zone just makes your life a lot easier cuz now I can just pass this to Dayjs and parsing done. No wondering continuing to prompting. So, I like to prompt in Markdown, but I've actually started to prompt in XML. Anyone here who isn't sure what markdown or XML is? I think we're pretty technical here, right? Yeah.
Anyone who's not a developer, >> I know Google markdown. >> Cool. Um, XML. >> Yeah. >> Awesome. So, why markdown? Well, if you look at Google stocks and if you look at um all the best practices that Google suggests, you see plain text and it makes sense. You can prompt your model in plain text. Just have good instructions and uh paragraphs and explicitly explain what you want. uh and many more best practices like for example only having positive statements as you can see here for example we tell
it to base every statement exclusively on the details provided by the user this is a prompt that extracts job experience from a CV um and I could also say don't invent anything but what experience shows and also what providers like Google suggests is that having positive statements makes the LLM more likely to follow your instructions So markdown in this case also helps us put more instruction to the prompt. LM reading it can save this in in in the cache while generating more content to recall
specific instructions. Different models have different training. For example, Claude uh apparently works better with XML while the open AI docs state that markdown is what they like the best. For Gemini, I feel like I feel uh XML works pretty good. Markdown works pretty good. Plain text works pretty good. I started writing a lot of prompts in XML recently. They're a little bit ugly to read, but I find that also for complicated topics where a lot of thinking is involved, that quality can be quite
a bit better. I'll leave that to your experiment.

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: tHrXptG4ipI
Language: n/a
Source: description-fallback
Saved At: 2025-08-17T10:33:10.157776
In Part 3 of the Building Enterprise-Grade SQL Agent series, we dive into how to reliably get structured output from LLMs. You’ll learn how to design system prompts, use message classes like AIMessage and HumanMessage, and validate outputs with Pydantic. We also tackle common issues like partial JSON responses and show how to extract clean data from model outputs — essential for any production-grade LLM integration.  #LangChain  #Langgraph #SQLAgent #RAG #OpenAI #FastAPI #LLMApps #ChatbotDev
#GPT4 #AIEngineering #MemoryStreaming #ProductionAI #StateManagement #agenticai

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: Rpg9TQtqqhE
Language: en
Source: auto-generated
Saved At: 2025-08-17T10:33:11.492542
So we've all seen the text responses from large language models and these are very useful in many scenarios. But ultimately text is unstructured data. It's very difficult to extract precise information from raw text. And because of that it's also difficult to integrate that raw text with other systems. Let's look at an example. We might ask a model about Bill Gates. Who is this guy? And it's going to give us a response and that response might look like the following. But this is just textual
data. Your other systems might need this data in a more structured format. And we can use structured outputs in llama index or in other tools like langchain in order to achieve this. So for example, if we use a JSON schema, we can turn this textual output into a structured JSON format. So we can see we have the name field, we have the nationality and so on. So it's taken that raw text data and it's transformed it into a structured format. In this case, it's JSON data. We can also do this with
Python classes, for example, pyantic models. And here's another example of the schema we might have for a pyantic model. And we're going to see how to use lama index in this video to achieve this transformation from raw text into a structured pyantic model class. And we're going to take the raw text from a PDF and we're going to turn that into a class. So before we get started, if you want to support the channel, check out our coffee page. And thank you very much to everyone that's contributed
to that. It's greatly appreciated. So let's dive in and don't forget to like and subscribe as well. Now the introduction to Lama Index is pretty simple. This is one of the leading frameworks for building LLM powered agents over your data. And the other big framework that's similar is Langchain. I'm a fan of Lama index, but Langchain is also very good for these kind of workloads. So, I want to start with a quick overview of Llama Index. It offers nice integrations with things like vector
databases, good tools for data processing, and it also offers integrations with the main LLM providers, for example, OpenAI, Gemini, and so on. Now I'm preparing a vector database course and I'm going to release that hopefully quite soon and it's going to dive much more into this particular framework but for now let's focus on structured outputs. Now I'm going to open a page from the documentation. I'll leave a link to that below the video. This is the Lama index introduction to structured data
extraction and the idea as we've explored at the start of the video is the ability to turn regular human language into specific regular and expected formats for consumption by computer programs. And as you can see in this last paragraph here, the core of the way structured data extraction works in Llama index is using Pyantic classes. Now, if you're not familiar with Pantic, I did do a series on that. I'll leave a link to that below the video as well. In a nutshell, it's a widely used data
validation and conversion library in Python. So, if you want to define a Pyantic model, you subclass this base model and then you have the fields that you want on the model as well as the type annotations. Now, there's a section of this page that I want to highlight. This is really important for understanding how this works and it's the conversion of the pyantic objects to JSON schemas. So what you can do is you can take the model representation which is essentially the class and you can turn
that into a JSON schema and I'm going to show you how to do that in a second with a real example. And as it says as well in this documentation if we go to the section on using annotations LLMs are essentially going to use the JSON schema that Pantic has produced as we saw above as instructions on how to return data. Now to help them out, what you can do is be more explicit with the fields. For example, you can define a field and give it a natural language description that is going to be
converted into that JSON schema and sent to the LLM and that's going to help it understand what the particular field is. So using these annotations can also help get better outputs from the models. Now, as I said, I want to look at an example. So I'm going to open VS Code and I have a completely empty directory here. What we're going to do is initialize a project using UV. We can use the UV init command for that and that generates that on the left hand side. Once we've done that, we can add
Pyantic and we're going to demonstrate how it generates these JSON schemas from the class. So we've installed Pyantic. What we can do now is go to main.py and we can paste this example from the documentation. So I'm going to copy this code and let's paste it in here. And if we go to the top, we can bring in the imports needed for this. So what we're doing is defining a line item and an invoice class. These are subasses of Pyantic's base model, which means that they are going to be model classes.
And now we can turn them into a JSON representation. So if we wanted to turn the line item into JSON, let's copy the name of the model. And if we go to the bottom, I'm going to import something from Python's print module. And that's the print function. And by the way, that stands for prett. And what we can do is pretty print something to the terminal. We're going to take the line item model and that has a static function called model JSON schema. So if we execute that function on the line item
class and it's important to note this is not on an instance of the class. We're executing this static function on the class itself. So model JSON schema is going to generate this JSON schema for the model class. Let's see that in action by going to the terminal and I'm going to clear what we have here and we're going to run the UV run command and it's main.py. When we run that, we should hopefully see the pretty printed JSON representation of the line item model. For example, here we get the
description and it says a line item in an invoice. We also get the properties with the different fields on the model such as item name and price. Now, where are these coming from? Let's go back to line item. We can see the dock string here, a line, item, and an invoice. That's actually what is turned into the description in this JSON data. And we can see the fields here, item name and price, and so on. And that data is represented under the properties. So we've turned the class definition into a
JSON schema and that is very useful. That's what's going to be sent to the language model to help it prepare this data in a structured manner. So I now want to move on to a practical example using llama index. So let's go to the terminal here and we're going to run uv and we're going to install llama index like this. So u add lama index and that's going to install that into this environment. And while that's installing I just want to look at this lang chain page here. So lang chain also supports
structured outputs. If we look at this diagram here, you can see that it takes this natural language. I'm Lance and I like to bike and that is then passed into the model and there is some schema definition underpinning that. In this case, it's got two fields name and interest. And then the model can process that alongside the schema definition and it produces the structured output with the name and the interest in a dictionary. So again highlighting the process of natural language being
converted into a structured output. We're now going to look at this PDF and this is going to be the dummy data for this video. We're going to turn this into a structured output and I'll leave a link to this sample invoice just below the video. So I've downloaded this PDF and if we look at VS Code here and we bring back the sidebar, we now have this data directory that contains sample invoice.pdf and we're going to read that into our application using llama index. So let's go back to the Lama
index documentation and I'm going to search for an object here and that's the PDF reader object. Let's go to this page and this is one of many objects you can use to read in data. It has a load data method and if we look at the left hand side you can see all of these different readers that are available in llama index out of the box. So we can use this with air bite air table and so on. There are so many readers here and we also have ones for databases like Chroma vector database and couch DB
and so on. Now in order to turn this PDF file into a structured output, we need to actually read the PDF in. So we're going to use this PDF reader. So let's go back to VS Code and I'm going to remove all of this and we're going to paste in some code here. So we've imported PDF reader from llama index. We've also imported pathlib.path and we've instantiated the PDF reader. we can now use that PDF reader to actually read the contents of the sample invoice. So, we're going to get a variable back
here called documents and we're going to take our PDF reader and we're going to call that load data method and we can pass a file into that. You can see we're referencing the sample invoice PDF that we have here on the file system and that's going to give us back an array of different documents. In this case, it's going to be a single document inside that array. So what we can do is we can get the text from that by indexing in at documents index0 and that gives us the document and we can get the
text from that using the text property and let's just print the text to the terminal. Now we can try running this by going to the terminal here and we're going to rerun the uvun command. We're running main.py and hopefully we're going to see the text from that invoice appearing on the terminal. Now you can see the output has appeared here and if we look at what's actually in the text you can see things like addresses and email addresses. We also have order numbers, invoice numbers and so on. Now
it would be very useful to extract some of that out of the raw text and store it in a structured format and that's what we're going to do next. So let's go to the top here and we're going to import the base model class from Pyantic. And we can now define a class and I'm just going to paste this in here. And we also need to import datetime. So let's just bring in the datetime module as well. And we're what we're doing here is defining a class called invoice data. And this is going to be the
structured output that we want to get after processing from the LLM. So the invoice data has some fields here such as vendor, invoice date, due date, invoice number, total due, and also items which is a list of strings. And you can see the typing going on here. Now I've added this comment here, convert to datetime. And this is one of the things that Pyantic is going to do. what we can see here if we go down to the text that's been extracted. Now, let me try and find one of these dates. It's the
invoice date from the actual invoice. So, if we go up here, we can see some due dates and invoice dates. What we want to do is take that string data, that text data, and we're going to convert it or coers it to a date time. And that is possible with pyantic because of these type annotations. So, let's try and do that. Now, we have the python or the pyantic class. And once we have the model with our structure, we can use Lama indexes LLM integrations for example with the OpenAI models. So let's
go back to the documentation and we're going to see how to use structured LLMs. The highest level way to extract structured data in lama index is to instantiate a structured LLM. So let's go down here and we're going to see what we need to do. Now the first thing we're going to do is install this. If you want to use the OpenAI models, we need to install Lama index LLM's OpenAI. So, let's go back to VS Code and I'm going to go to the terminal here and we're going to run uv and we're going to
paste that in there to install that. And there's another package I want to install and that's python.in and that's going to allow us to securely read in data from a. Now, once we've done that, we can go back to the documentation and here we can see similar PDF loading classes or code here and this is using an Uber receipt as the PDF. So, we're going to pick this up from here. So let's copy this import and we're going to bring that into the top of the file. We're importing OpenAI from the llama
index.lms.openai module. And this gives us an interface for working with OpenAI modules. And if you don't like OpenAI, there are plenty of alternatives in this LLM module from Lama index. Now once we have that, let's go back to the documentation. What we do is we instantiate the OpenAI object and we provide the model we want to actually run and that gives us back this LLM object. We can then call a function called as structured LLM and we pass the class that we want to actually use as the
structured definition into that function and that gives us back this S llm or structured LLM which we can then call with the complete function and pass any text into. Now the text here is the text that's coming from that PDF. So we're going to replicate this workflow here. I'm going to copy these lines of code and let's go back to VS Code. Now, if we go to the very bottom here underneath where we have the text from our PDF, I'm going to remove the print statement and paste this in. And one
change we need to make is we need to use the right class and it's called invoice data. That is our pyantic model class. And we pass that to as structured LLM. And that's going to return a structured LLM around our pyantic model. And finally, if we go to the bottom here, we get a response by calling the structured models complete method and passing the text that we extracted from the PDF above into the complete method. Now, we're not going to run this yet because in order to interact with
OpenAI's models, we need an OpenAI API key. Now, I installed Python. And that means we can create a in this directory. And I'm going to add a variable here called OpenAI API key. And I'm going to paste mine into this, but I'm not going to let you see that. So, we're going to cross over to main.py after I paste that API key in. So, we're now safely back in main.py. Let's bring in the load.n function from the end module. And we can just call that to load in the environment variables from the end
file. And finally, we're ready to start looking at the response from the model in this structured format here with the invoice data. So, let's go back to the documentation and we can see how to do this. Now response from the above method here that is a llama index completion response and it has two properties and that's the text property and the raw property. Text contains the JSON serialized form of the paidantic ingested response and that sounds a bit complicated but we can see the response
here in that format. So it essentially takes the pyantic model and dumps that to JSON data and we can see that JSON data here. The important thing though is that this is not a text response. It's a structured JSON response that has the fields and values that we expect based on the model definition. So let's see an example. I'm going to copy this line of code or these two lines of code and let's go down to the terminal here and just below the response we can print these in. And I'm just going to
go to the top and we need to also import the JSON module from Python. So import JSON. And now we can look at this response and see what's coming back. So let's bring the terminal up here and we're going to clear what we have. Remember this is only going to work with OpenAI if you define that OpenAI API key. So let's run UV run main.py and we can see what we get back from the language model. Hopefully a structured format on the terminal when we dump that to JSON and we can see the response that
we have here. Now this is quite interesting. What I'm going to do is bring the invoice on the right hand side so we can compare what we have here to the actual invoice. So I've now got this sideby-side comparison and let's start with the vendor here. It's got the vendor as demo sliced invoices and that corresponds to what we can see here at the top of the from section. And the invoice date is the 25th of January 2016 and the due date is the 31st of January 2016. And you can see that that
actually matches what we have here in the invoice. So it's extracted that specific data into this structured format. And that is super useful for downstream applications that you are integrating these responses with. We have the invoice number here and you can see that at the top of this table as well. And the total due is $93.50 and you can see that here. Now the final thing we've got here is items and that's an array and you can see the web design item and also the subtotal, the tax and the
total and it's getting these keys and values from this bottom section of the PDF. So I think this is super powerful. We've taken the raw response from the language model and instead of just raw text, we've converted that into a structured output. In this case, it's JSON data from a pyantic model. Now, what we did was we took response.ext and we loaded that from JSON data into a Python dictionary. And then we dumped that to the terminal and we indented it by two. So, essentially we loaded it from
JSON to a dictionary. And then we converted it back to JSON data just with better indentation. Now, I'm going to show the other property that we have. And remember, the text property is one property, but it also has a raw property. and that is the completion response object in llama index. So I'm going to create a variable here called invoice data and that's going to be response. And I'm going to remove these two lines of code and I'm going to paste in a couple of extra lines. So this invoice
data is actually the raw pyantic model. So what we did above here is we passed that model into the as structured LLM method and the response that we get back when we actually query the model. thet raw property of that response should be the piantic model with the fields and with the correct data. So what I'm doing here at the bottom is I'm printing the type of the invoice data. Hopefully that's going to be a pyantic model and we also print the actual object itself. So let's go to the terminal
again here. Let's clear out what we have and we're going to rerun uvun main.py and we're going to see what we get back. And we can see the response that we have now. So the type is the invoice data class. That's the pyantic model. And underneath that, if we print the object, we get the representation of that object. Now, this is super useful. Once we have that object, we can actually access individual fields on the object. For example, if we wanted to get the vendor, all we would need to do is
go back to the bottom here and I'm going to add a print statement at the bottom. We're going to take the model and we can use the vendor property on the model to actually access that individual piece of data. So, let's clear the terminal. And one more time, we're going to run main.py. And you can see from the output now we can actually extract that single piece of information that represents the vendor. So this is so useful. We now have an object that we can use in our applications and
downstream apps which could be for example airflow tasks or Dagster assets or machine learning models, web applications, whatever you want. databases of course they can all use this structured data and that's going to be super useful because they can extract the specific parts of the information that they require and that's going to be much easier to work with than raw text. So as useful as this is there are some caveats here. Now the pyantic validation that we get based on this model that we
define is not a guarantee. You should be testing your data thoroughly when you use structured outputs and validating that what you get back is actually matching the schema and the values are correct. So you can make sure that you're testing thoroughly to make sure that you're getting what you expect as the values for these fields depending on your input data. But once you have this in place, it's of course super easy to add and remove fields from the models as you require. And these pyantic
models are super nicely integrated into Llama index. Now I just want to finish by noting that this functionality is not only available in Lama index. As we saw earlier, it's also available in lang. So for the lang chain enthusiasts out there, this is going to work nicely with that particular package. And there's also a nice package in Python called instructor. And this is a package geared towards specifically producing structured outputs for LLMs. Now I'm planning to do a video on this and it's
going to be somewhat similar to this video, but if you're interested in that or any other content, let me know just below this. And again, instructor is nicely integrated with Pyantic for defining the structure of the outputs. So, we can look at that in a future video. If you found this one useful, give it a like and subscribe to the channel for more. And if you want to support the channel, check out our coffee page. And again, thank you to everybody that's contributed to that. It's greatly
appreciated. And we'll see you soon in the next video.

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: 3Q31aObRBMo
Language: en
Source: auto-generated
Saved At: 2025-08-17T10:33:12.840484
Hey everyone, this is Evani and today we continue our pre-built agents in Langraph. So welcome back to Lang Graph and Van series. Uh my plan for today was to check how uh structured output works and what options you have there. So join me in the session and let's learn this together. Okay. So we are looking at structured output today and first let me define some basic stuff like we still need tools. We need let's start from the basic agent here and it has very little at the moment. It has a
model defined. It has two tools and the very basic prompt. And the way how agent looks like is very simple and straightforward as well, right? And let's try and ask something like analyze stock symbol TSLA and provide a financial summary. And this I already have to mention today. I'm not going to uh search for or ask for a tool call to recognize what Tesla what which stock symbol Tesla has because well I run to the limits of this API. So this tool is not working for me today like uh this free
key is obsolete at the moment like until tomorrow and so I will be making the whole process for the edit more simple. I'm providing myself that Tesla is TSLA and I'm saying that this is stock symbol. So it's clear for the model that okay this tool is not necessary the first one to define the stock symbol. Anyway we have the very simple graph and let's run the query for analyzing stock symbol and see the results. And here we are. The expected result is as expected, right? We have this TSLA and it
was a direct tool call for fetching stock data. And we do have a lot of data as usually. Nothing is really new here. So, let me scroll it through very fast. And at the end, we have the EI message from the model that uh contains some summization about the Tesla company, risk opportunities, and so on. And what's the problem is that uh the output here is very good I would say right but the problem here let's assume we are not well it's good only if the application we are creating is a normal chat
application so that's fine right we do have some output we can show it to the user and practically that's it we ask user to make all the next steps but let's just imagine that you're working on an application which has to do something on top of that for example it's a it's not a chatbot. It's it's a financial bot which can sell or buy the stocks for example, right? And in this case it's more sophisticated because at the end you have very row text and it has you have to do something with this and
here where we need the structured output. So we want the model to generate data in a specific format which is well distinguished and which we can use to make our decisions in the future. So this is why uh what's structure output in essence and uh basically we talked about that already in lang graph introduction series if you don't know about that please refresh your memory look all this videos and today we are talking about structured output only in connection to this pre-built agents so which
way we are doing this first of all we have to define our model and this will be financial info and I'm using pantic library so I can describe my fields and again those give the model some additional hints what should be in the field and how to format it maybe possible values etc and in the financial information model we have company name which is Tesla in our case stock symbol if this is TSLA and we ask it for current price and market cap as well then we ask the model to provide us some general
basic summary here as well and risk assessments well uh this is the tricky part right uh if your if your application needs something more you just change the model and ask the model to provide the specific field. So this is the key idea and so we have the model class this is financial info and then we just generating our agent and the only new information really here is that we are defining response format financial info and that's it but let's look how this agent uh differs from the one that we
created before that so I'm compiling that and look at that we do have a new note with the name generate structured response and the way how it works we still have this loop of uh calling tool and reasoning And once agent decides that okay all the information is collected there is no need to call another tool. The agent would proceed to generate structured response and then this guy takes all the conversation like and using this uh financial information as a hint model generates the proper the
proper JSON format or it will be financial info data in Python. And to demonstrate you that well uh let's do this thing we make an invocation of this model again and the same question. So analyze stock symbol TSLA and proide financial summary but this time I want it to be structured and I have back the response which contains a lot of data like all the messages for example. But uh when you have this note you have additional key structured response and you can fetch it directly here and then we
just uh dumping it and showing as a JSON because again this structured output would be of type uh this one financial info. So I'm running it and look at that instead of all this row text explaining what Tesla is we do have this structured block of information. So we have company name Tesla stock symbol we have the current price market capitalization as well we do have some summary and we have risk assessments and everything was generated by the model for us what you need to understand here and I
noted uh below that uh for generating this another LM call happened. So on this note there's another LM call and this is very important information you need to consider in the future. So for example, if you go into landsmith and check the latest call uh look at that. So what do we have here? We have uh call model agent it was for fetch stocking data and back when we have the data the agent decided okay everything is fine and in this state it generated I can show it to you here but believe me
this how it works it generated the row um how it's called report and then uh agent decided okay it's enough information for process here and send it further to the generate a structured response and here we have another LM call right and with the older data the response was this pretty uh well definfined JSON in the standard we needed so this how it works and why I'm saying that's this is something important you have to consider well because in general you have some drawbacks of this solution
well first of all and maybe the most important one there's an extra API call every uh time you call the agent and you have to consider it because you're paying for that and it's extra API cost on top. So you need to think about that. If this is a critical for you, you can think about different workarounds how you would uh try to avoid this extra cost API calls and maybe losing some control over the several nodes, right? And one possible workaround and again we know this from our previous L graph
introduction series. We can use uh this financial inform model as a tool. So tools not only our function which performs something but you also can provide your model as a tool and then LM is clever enough to understand that and when you execute the tool it will generate you the same kind of response in a proper format. So this is the idea and for doing that uh what we are doing look at that uh we have a system prompt and this time it's a bit more verbose. So what we're doing here we are just
providing tools and we're adding another tool which is our model. So it's here and the rest is the same. And if I compile it, we can see the same kind of graph right we had previously. And uh now we know that under this tools we have our model as well. So our hope is that at the certain time agent at the last step maybe agent would realize okay I have all the data and now it's time to call the generate model thing to the tools and generate it and send us back. And if we check it, let's take a
look the same question about stock symbol. And we're just pretty printing all the messages here. And uh if we check it, look at that. We have the request from the user. We have a tool call. We do have some response back from tool. Let me scroll it through again. And uh here we have another tool from the model model and model already instead of providing this row explanation it puts a lot of arguments based on analysis already and from this uh financial intro info tool we do have the proper
generated JSON kind of and then model having that responded back with the JSON so everything works fine right uh yes with one exception you don't have specific uh this specific piece of information collected it somewhere it's in the list of messages and then this is up to you have to probably pick the latest message from the conversation you have to think about okay then this is a JSON you have to parse it and you have to do all this kind of stuff right it's not so convenient in the end of the
day and uh well practically I was saying that right this is a workaround so keep this in mind it's not it might be not convenient in all the aspects but it's kind of if you want to reduce your API costs then you can go this way But uh is there a way you can improve this? Like you don't you're not looking for the latest uh message here but just do something on top like and you get back from your graph exactly the same response as previously. And for that we can reuse this uh postmodel hook. This
is another possibility of pre-built graphs. And the way it works uh well uh you define a function that's been called by the model and then this function can decide if the uh state should be updated or not. And what we're doing here uh let's take a look practically I told you already what should be done right we we took the latest message we double check if this message is a tool call and if the tool name is financial info this exactly our model name and if so then we are updating our current
graph state with structured response key and providing this financial info and then we are trying to parse it and again this is up to you because whatever can happen when you're parsing this JSON right and you need to react on that so it's more verbose way at the end of the day like but you're doing this kind have a workar around. I'm mentioning this again for you that uh it's it gives you more control but it gives you more responsibilities as well and also you have to uh this is a tricky part
like I'm trying to add key here response structured response and basically our model doesn't know about that so we have to redefine our model as well so I'm creating a new model here our state graph state it's a state and it's based on message state so I don't have to add messages and we have proper list of messages including reducers and all this kind of stuff create already. Uh we do have remaining steps and this is a necessary if you check the documentation about pre-built uh graph and all
the parameters and says that messages and remaining steps keys should be there and we adding structured response as well as an optional field. So what's happening next? Uh look at that. We have the same prompt. We have the same list of tools including financial info and finally we are adding postmodel hook with uh filling it with our function and this time uh this one was introduced only in version two of the function. So we have to define this v2 as well and the rest is the same. Yeah and agent
state we have to define the one we created here. So for state schema if I compile it look at that how it uh looks right. Uh this is very interesting what's happening all the time. It goes from the post model hook and it then go uh it can go either tools and go to agents and the loop happens reasoning again or it can finish. This is the two path that we're interested in right and since we created our possible hook that it reacts only and it updates this state only on the case where we have a tool
call from our specific model. Well this is the case where it should trigger should be triggered and goes to end. So let's take a look and see how it works and the same kind of graph and uh well I know I'm looking for structured response there but this time wire post model hook and I'm pretty printing it and voila we do have it again the structured output with the proper object was created so this was another way but again keep in mind it's kind of all has pluses and minuses and here we are
reducing one additional cost but at the same time we have a lot of responsibilities like we have to do this manually on the post model hook if parsing is failing then it's your problem at the end of the day right you have to do something with that um so just two different options how you can do the same with pluses and minuses and traditionally if you are interested in that in digging into details maybe learning something on your own I'm providing your some reference links here at the end of
this uh playbook so you can grab and read it on your own and try it as well all right that's it for today we check together how structure outputs work in L graph when you're creating pre-built agents. For the next video, I think we're going to check how all these uh pre-post hooks working together, how you can set the break point. Well, we we saw it a bit already in this lesson and we continue in the next one. And it was me again. Thanks for watching till the end. I really appreciate it. Leave
your comments. Uh say what you think about that. Maybe you have your own experience. and I will see you next time in the next video. Thank you and bye-bye.

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: fmBu51tlMJw
Language: en
Source: auto-generated
Saved At: 2025-08-17T10:33:14.116438
Hello, how you doing? Have you heard of a strategy in prompting where you specify to the LLM that it should generate structured output such as JSON or XML? Are you familiar with the use cases that really benefit from using this technique? Well, if not, then watch along with me for the next few minutes and I will quickly get you up to speed. Okay, let's get started. So, what is structured LLM output? Structured output refers to machine readable formats like JSON or XML where the LM responds with
clearly defined keys and values. These formats can be parsed directly by Gentic systems making the LLM output more deterministic and usable in LLMdriven pipelines. In simple terms, you're asking the LLM to speak in a format that your code can easily understand and act on. So imagine a use case where you want the LM to extract key information from a customer support request and return it in a structured JSON format. Here's an example prompt you might find in this use case. We start by telling the
LM you are a helpful assistant and you are to extract information from the customer request which you will use to populate a JSON response. In the prompt you can see I explicitly share to the LM the requirements for our structured JSON format. Next you can see I provide a customer request which the LM should use in extracting the customer information. You can see the customer request is unstructured free form text. Finally, the prompt instructs the LLM to return the results as a JSON response.
For this example, here is the JSON response the LLM returned. So why does structured output matter in programmatic or Aentic systems? Well, when building these systems, structured output ensures seamless integration with back-end logic and databases. LMDriven systems involving form automation, document extraction, or user assistance rely on predictable structured output to function reliably. Prompting for JSON or XML structured outputs helps LLMs go from free form text generators into reliable
components inside real software systems. Another benefit of structured outputs involves logging and troubleshooting. Structured output allows systems to more easily verify correctness and completeness. Simply put, it's much easier to analyze logs and troubleshoot when the LM always returns output in a consistent shape. You don't have to guess what the LM was trying to say. Instead, you can just check fields and catch issues automatically. So, why does all this matter for production systems?
Well, structured outputs make LLMs more reliable, safer, and easier to integrate into realworld agentic and LM driven systems, especially where consistency is critical. They enable modular architectures where agents, tools, and services can collaborate with confidence using shared data formats. So whether you're building a genetic platform or automating business logic, prompting for structured output is essential for production grade systems. Let me know what you think of prompting for
structured outputs. Are you using this technique in any of your LM driven systems? Feel free to share your thoughts in the comments below. I want to hear what you think about this topic. Okay, thanks for watching this video along with all the other videos in this playlist are listed in the YouTube description. I invite you to watch other videos on my channel. If you like the way I'm sharing this content, please consider subscribing. When you subscribe, this really helps my channel grow. One last
thing, we all love technology and we're all excited about all the innovation with the cloud, machine learning, AI, but don't forget to carve out some time to live in the real world. Go outside, go swimming, go hiking, go climbing, go surfing, but get out and move your body. And if you do, let me know in the comments. I want to hear about this as well. And with that, have a great day. Thanks.

===== END TRANSCRIPT =====

