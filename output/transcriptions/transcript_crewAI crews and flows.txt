===== BEGIN TRANSCRIPT =====
Video ID: RyYTISPL3vQ
Language: en
Source: auto-generated
Saved At: 2025-08-26T05:31:41.171284
Hey there, this is Ax Manaran and welcome back to a new video. And in this video, I'll be showing you Crew AI flows. We'll be talking about the significance of these flows, how you can set it up and mainly why do we need this concept CUI flows. So first of all, you need to understand CUI flows are important if you are creating AI workflows. Okay. So what is this AI workflow? So let me take an
example. So in the previous video we had created a cube. Okay. And we called it as marketing crew. But if you see that is not a marketing crew. It it cannot handle marketing end to end. So if you are thinking of creating an AI agent system or an AI app that can handle the complete marketing for you, that crew which we created in the last video cannot do it. It can only do 5 to 10% of the work
because that crew that we created had three agents. First agent was content researcher. Researcher, right? The second agent that we had was the content writer, right? It was the writer. And the third agent that we had in the crew was the reviewer. So can you see over here? Can these three agents are enough for handling the complete marketing for a company? No. So we can say that this is just a
crew and we can you know call it call it as content curation crew. Okay. So this is just one single crew. It is not a marketing workflow. It is not an AI workflow. Okay. So understand the difference between a crew and a AI workflow because in the documentation in the documentation of CRUi you will see under flows learn how to create and manage AI workflows using CUI flows. Okay. So we have now
learned how to create a CRU till the previous video. Now understand if you want to handle uh complete marketing for a company or a client using AI agents then you need to have or you must have multiple cues in your system. So this was one simple crew which can curate content for you right but in a marketing AI workflow just content curation is not enough you need to publish the content also right
so content publishing crew okay or one second yes content publishing crew because in marketing you have to curate the content you have to publish the content you have to monitor the content what is working what is not working if any leads are coming then you have to handle those leads also. So there's a complete workflow. But for this particular use case, let's say that there is in our marketing
AI workflow, we only have content curation and we have content publishing. At least our content can go out with the help of AI agents. If we create this workflow, okay, so from that workflow, this CRUi flows is coming. So CURI flows are important when you when you want to have multiple crews in your AI system or when you are creating an end toend AI workflow. Okay. So for content publishing crew
the first one will be uh SEO checker because before you publish your content you need to check the SEO score for your content if it is good the metatitles uh the tags what is uh what like which all SEO terms will be good which all keywords will be good. So for that right so SEO checker uh will be the first agent in this content publishing preview. The second one will be publisher right the agent
that can publish the content on your blog website or on GitHub or on social media or on medium right anywhere. So it is this is going to be your publisher and the third one will be your notifier notifier right which actually sends an email to all the subscribers of your content that hey we have published a new content please read this right so if you do this and you you can also understand that
this content publishing crew will only work once it receives the output or output from the previous crew or it understands by somehow that the crew the previous crew the content curation crew has completed its task. So that thing we do using states. So let me take it over here. Okay. Uh let's remove this. So we also have a con concept of having a state and this state can be accessed by any of the
crew right. So this state remains a global variable or global uh memory kind of thing, right? So that any crew can update this state and any crew can also read this state. So this is important because what will happen flow and this state exists at the flow level right? It does not exist at the crew level. So uh as soon as we have received the final content from content curation crew the that blog
markdown will get updated in the state right and as soon as that blog variable in the state gets updated this content publishing crew will understand that the previous crew has completed its task and now I can pick up that blog and I can do the SEO checking publishing and notifying on that blog piece on the content piece. So this is how uh thus communicate can communicate with each other right
using with the help of states okay and the complete thing and yes there can be multiple crews uh the complete thing is called a flow okay and using flows you can create such systems so let's quickly go through this documentation because it is very good I read through it and then we'll just try to uh Take a simple example. Okay. So, learn how to create manage AI workflows using clear flows. Uh you
can use you can create simplified workflow creation, state management, event- driven architecture. This means that as soon as uh like this crew completes its task that acts as an event for the another crew and then the another crew gets triggered. So that is called eventdri architecture flexible content flow control flow and then over here like this. So these two methods are very important in a
flow. So like this you create a flow. Okay, you define a class flow and then you define which model you want to work with. Then these two methods start and listen. Okay, these are very important because the start decorator will hold the function uh which will contain the first step that needs to be done. And definitely the first step might not always be the triggering of a cube. It can also be a
simple uh LLM call like this. And I'll come I'll scroll down and I'll show you like how the how such system can be built using flow. But just a minute. So over here what is happening in this flow. The first the flow gets triggered by calling an LLM call. Uh by calling the LM it receives a response and then you can see it updates a state. Okay. So the question was from the LM return the name of a
random city in the world and it is going to return your city name. As soon as we get the city name we update the state. Okay. And as soon as the state is updated, you see over here the next function, the next decorator at listen. And this listen is going to listen to this function generate city. And you see we have the same function name generate city. Right? So as soon as this generate city
returns something, this listener or this function will automatically understand that now it's its chance to get triggered because the previous function has done its processing and it's done, right? And now using the state we can actually get that generated city and we can generate a fact about that random city. You see random city we can get it. So like this and here we do not have crews but over
here instead of this LM calls we can also have multiple crews. Okay. So let me let me scroll scroll it down and yes using this crewi flows you can also generate the diagram. So first one was generate CD the second function was generate fun fact and both of these two are the parts of the same CUI flow. Okay. So yes, we have start, we have listen, you already understood the meaning of these two. We
have flow output. Yes. Yes. Yes. This is all good. State we already understood. So we can also have a state class. I'll show yes over here. So this is a state class. So over here the flow gets uh the flow is getting created. But over here this is a state which holds two variables counter and the message. And these two variables will get updated as the flow functions will run and generate
something. Okay. So like this this is three-step flow. First method, second method, third method. Right? And these arrows shows that the second method is listening to the first method and third method is listening to the second method. Okay? Flow persistence is using state itself. You can just give it a lighter light read. And now let me show you crew. Let me show it to you where it is adding
crews to flow. So first of all, this is the command using which we can create a flow in. So let me just copy it. go to my VS code, activate my virtual environment. Okay, it is already activated and let me come out of marketing crew and I'm in learn folder. I'll paste it create a flow and let's call it as poem flow because I see in the example they are creating some kind of poem crew basically. So
let's let's call it as or let's call it as sample flow. Okay, let's see what we get. flow is created. Now a flow will have a cruise folder. Okay. So you see you see can see the folder structure that will get generated. Now this flow sample flow will have multiple crews. Okay. So if I show you the source folder cruise folder and in this crew we can have multiple crews. So currently as you can see
as you can see we only have one crew but you can have multiple crews inside this flow. Like in our case, we had the content curation flow and we had the content publishing uh sorry content curation crew and we had content publishing crew. Okay. So you can have multiple crews in this uh folder. Okay. But for now let's keep it simple and let's have this poem group. So in this poem crew you have
again agents and task. So we only have one agent which is the poem writer and this is the task. There is no tool for now. And in the main uh in the in the poem crew.py we again we have already covered this. So we have a poem crew which is decorated by this decorator. We have this agent and task and we are getting the agents and task from the configuration files. Right? Then we define the agent
poem writer. We define the task the write poem task. And then we have a crew which actually runs and writes a poem. Okay. So this is like one simple crew. Okay. Now in the main.py Pi you are not directly running that poem group okay so first of all you have a state this state has two variables one the sentence count let's say you wanted to have some limit on the sentence count of the poem and
using this variable you will be able to control that let's say a crew poem crew returned a poem which had like let's say 100 lines but your limit was 50 lines then you can again ask the crew to regenerate a po poem with this feedback back. Okay. So you have the poem. So this here the final poem will get stored. Then we have the poem flow. A poem yes poem flow which actually is um also taking this
poem state in context so that we can save the variables or the data that is generated in this poem state. And then we have the start and we have the listen. Right? We already know the significance of these two. Start will be the first uh thing that gets triggered when a flow gets triggered. Right? So it will print generating sentence count then it will initialize it with five or like any random
integer between 1 to 5. Okay. Then the second one because this listen you can see generate sentence count it is listening to the previous the first function as soon as this uh state will get updated this uh function the generate poem will get triggered. Okay. So it will print generating poem and this this one this listener like uh the second function generate poem this one is going to trigger the
crew. So like this as we have already uh understood like how you trigger a crew you create an instance of the crew then you say dot crew then dot kickoff and then you provide the inputs sentence count like hey of this much these many sentence like these many sentences I need to create a poem and as soon as you generate the poem you get it in the result and then you update the state back you say
selfstate poem is equal to result and your poem will get stored in this state right now. You can also have another listen like another decorator which is now listening to this generate poem. You see generate poem. So this one will get triggered as soon as my state of the poem will get updated. Okay? Because I can only save a poem once my poem is generated. So save poem will only get triggered once
the generate poem function is over. So I'll just create a text file and I'll save that poem in a text file. Now you can have you can just have multiple uh functions also over here right so you see I just created two more and these two more can be triggering more crews let's say you wanted to have a publishing poem publishing crew or poem pub po poem reviewing crew right or poem metadata reviewing
crew some kind of other crew which does some more stuff on the poem right or a story writing crew right or a essay writing crew Right? So let's say you are some kind of English lover and you want it you create you create an AI agent that can write poems, stories and essays. So you can have multiple crews which can do that stuff for you. You don't you don't have to just create one cre and put all
the agents inside that crew. Okay. So like this you can work with flows. So let me just save it and let me just so I'll go inside this uh sample flow and I'll paste it flow kickoff. As soon as I do that, first of all, okay, yeah, it is going to like um install all the libraries because I created a new folder and definitely it will ask me to put the API key also. So, I'll do it. Don't worry. So, it
failed and it asked me for the API key. So, I've added my uh API key uh the Gemini AP or open API key. And now, let me try to clear it and run it again. Now let's see running the flow uh crew execution started and let yeah so over here it is starting uh starting flow execution poem flow id and there are no tools so so next thing is flow started with this ID generating the sentence count generating
the poem now my crew uh got triggered the poem uh writing crew so crew poem writer this was the agent we only had one agent write a poem that how about how crea is awesome. Ensure the poem is engaging and adheres to the specified sentences count of five. Okay. Then this is the agent it uh completed task. This is the final answer. 1 2 3 4 5 and then the CRU uh like status is completed. Assigned uh
like this agent status is completed. Task is completed and then creo is completed. Okay. Then this is the final output and after that we don't have anything. And then finally it it would have saved the poem. Let's see. So this is poem.txt txt file which got generated by the third function of my flow and I can see my poem over here. Okay. So like this I would highly recommend you that go ahead and
create two more crews for story writing for essay writing build this complete project see if you're getting all the outputs and then you can push it on LinkedIn and uh see that hey I I created this my I created my first flow on prei and you can thank me also. Okay so the code will be in the description. I I just used a sample boiler plate code. I did not write any code in this video. So you can
also go ahead and use this documentation, read it because I also learned flow by reading this page itself. So I highly recommend you to read it. Till the next video, keep coding, keep innovating and thanks a

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: 0Q2C1rqi9lk
Language: en
Source: auto-generated
Saved At: 2025-08-26T05:31:43.547233
Hey there, this is Ax Nunan and welcome back to the next video in which we are going to study about knowledge in a preui. So we know that if we are building an inference engine or like if we are building a agent so let's say this is my agent and this agent will be built of many components. So the first component very important component is going to be an LLM the brain right um and like very
frequently this agent will be in touch with this LLM it will make some request and LM is going to give it some response or we we also call it as a generation or the inference right and this agent is also going to have uh number of tools right we we know this right uh like the agent is going to have bunch of tools And this agent can make these tool calls. When LLM asks the agent to do so, then this
agent can make the tool calls. Okay. Another important thing that an agent has is the knowledge base. Okay. Uh the knowledge base uh because every time agent will not be having the full-fledged information or the context about what the user is going to ask or is asking, right? So over here we call it as the knowledge center. Now this knowledge center can be an external knowledge center or an
inbuilt uh knowledge center which is provided by many agentic frameworks like creat. Okay. But what exactly is there in this knowledge center? Let's say I'm building a chat engine which should be able to which is an HR agent, right? And that agent should be able to uh give responses to the employees if employees asking about a company policy, leave policy um or like um any other policy, right? So
the agent or the LLM will not be have will not be having any information about the company policies, right? Because these policies are uh created by the company, right? So this agent will not have information. So if you want to build this inference engine or a chat bot then you need to have this knowledge center attached to this agent. So that whenever there are two ways when if the company
policies are like very big bunch of documents and they are like thousands of pages then you can use something called a cloud vector database like pine cone right you can use pine cone um where you can embed your documents index your documents and whenever based on the user prompt let's say the employee is asking about the leave policy then that prompt will go to the pine cone and it will fetch
those bunch those parts of the complete document. It will not bring the whole document and give it to the agent. No, it will not happen like that. If the employee is asking about leave policy, the agent or not the agent but uh the query will go to the like this uh vector database and it is going to bring only those paragraphs which talks about the leave policy. So that our LLM is not bombarded
with a lot of information. Only those paragraphs which are having the information about the pol leave policy will go to the LLM and based on that the user will get the information back or the answer back. So this is called the external knowledge center where your knowledge is embedded or indexed on a cloud database cloud vector database right we also have chroma database right now there can be
like you can use this cloud databases the second way is uh if you're using cryi you can use the knowledge framework by cryi so what it does is it it does not use any cloud database yes you can forward your uh documents embedded documents to a cloud database also but if you are using knowledge by crew then it keeps the documents in your system itself. So I know it might get uh it might be hard for
you to understand. So let's go through this documentation and but instead of that let's build a crew and see what I mean by knowledge. Okay. So what I'm going to do is I'm going to create a new crew. So crew AI create let's call it as chatbot. Okay. Chatbot. Uh okay. I need to activate my environment. source venv slash bin slash activate. And let's create a crew. I'm going to use Gemini uh Gemini
1.5 should be good. I'll I'll put the APK later. And yes, our crew is ready. So you see this knowledge folder and you you can see a text file inside it. Let's delete it. So basically what I want to I want to say is all of the knowledge or the information that you want to give to your uh CRU AI CRU agent that those information you can keep in the knowledge folder okay uh again let's go and do it
like instead of talking right so in the crew.py Pi folder. What I'm going to do is first of all you can provide information to your crew in various formats. You can provide a simple string. So what this knowledge is doing is this knowledge will set the context for your crew. By crew means all the agents that are there in your crew. They can be four five agents, right? All those agents will know
this information will will be having this knowledge. Okay? that whatever uh which like whoever is talking with this agent or this crew interacting with this crew the name of the user is John and he's 30 years old and lives in San Francisco. So basically this knowledge will be helpful if you want to set the context for your crew agents. Okay. So I'll do the same. First of all let's use this string
knowledge source. So as you can see knowledge source. So there can be various knowledge sources. It can be text file, normal string, excel file, PDF file, JSON file, right? can be various uh formats, right? So, let's use the string uh for now. So, I'm going to copy this and I'm going to paste it over here and let's remove this from here. I I've just put the import over here. I'm importing string
knowledge source and over here I'm going to put the string source. Okay. So, the content is username is Axed. Okay. He is uh 24 years old and lives in Bangaluru, India. Okay, I'll save it. So when I'll be kickstarting this crew, all the agents of my crew will know that Axit is talking to this crew and he's 24 years old and he lives in Bangalore. I'll show you how that works. So I'll save it and
now just scroll down and you need to provide one more parameter to your crew which is your knowledge sources. So you can have multiple knowledge sources. Okay, I'll save it. And for now I'm just writing the string source which we defined over here. Okay, save it. And now uh I'll go back to agents and task configurations. I'll remove this and this researcher will be helpful assistant. So I only
have one agent and this role is going to be helpful assistant. Goal is going to be uh like help the user uh in some way right I'll remove this backtory will be helpful assistant and I'll go to task again remove this first task and the task is going to be helpful assistant task. Okay. Description you can give task for the helpful assistant to assist the users with the queries. The user query is the
user query is and you pro provide the question over here. Okay. So that the agent knows what exactly is the question that user is asking for. Expected output is going to be uh helpful assistant should provide a detailed information response and that's it. And this agent is going to be helpful assistant. Let's save it. Let's go to preview and let me remove uh all of this part and I have only one uh
agent like this and this is going to be helpful assistant. So I'll just copy this and I'll paste it and then this is going to be helpful assistant task and this will be same and let's remove this task. Okay, so all everything is looking good. Now I can go back to main.py. In the inputs I'm going to have only one uh like value which is question. So I provided the question who am I? And I expect the
answer to be like uh hey you're ashed something like that right because in the knowledge source I have given it this information. Now uh two more things as soon as you will run the groove it is going to embed this uh piece of information and that embedding will be stored in your local system. So if you want to know where exactly uh the embedding will be stored you can print the location in your
console and one more thing the embedding model right because we are going to need an embedding model and by default crea uses openAI embedding model so you need to provide the open APK in your environments and if you don't want to use openAI embedding model uh let's say you don't have the API key then go to this knowledge document uh page and search for embeder and And you're going to find that
like this you can change the embedding provider and you can put this in your queue. So if I just copy this if you don't put this it will take openai as your embedding model right so below this knowledge source you can put that parameter you can put the provider as Google and config this model which will be an embedding model and then you can put the Google APK in your in your environments and
that's how you don't have to depend on OpenAI as your embedding model. This was number one. Okay, let me remove this. I'll use open AI. Okay, second thing is if you want to print the location of the place in your system where ex where exactly this knowledge will be stored, right? Because this is a string, it needs to be converted to embeddings. So, and we are not using any cloud vector database.
So, we need to store these embeddings in our system itself. Okay? So, for that um I'll show it to you. Let's scroll down. Yes, this is the line finding your knowledge storage location. So just copy these two. Okay, go to your main and where we are running the run function there itself. I can I can print the location. Okay. And I'll import this. Okay. I'll import this. And this should be good.
Okay. So okay no I just imported the complete code piece only these two imports are required and we we are good. So first of all it is going to print the knowledge storage location then it is going to u basically embed my piece of information and then it is going to trigger the agents. So for now I'm not going to do this. Okay. I just want the knowledge path. Okay. Okay. So what I'll do is I'll
cut this and I'll put it over here. Let's try to uh run this screw knowledge storage location is this particular path. Okay. Go to like I'm using Mac. So if you're using some other system, you can check where exactly it is going to store it. Right? So this is for Mac, this is for Linux and this is for Windows. Otherwise you can print the path and then you can also check the location. So I'm in the
application support and if I see what exactly is in this I went inside chatbot because over here it told me to go inside chatbot and over here we should have a knowledge folder. Uh okay yes I see the knowledge folder and I can delete it. So if I delete it, RM dash RF knowledge and now it should not be there. Now if I go back and change this, let's say I want it to be storage knowledge. Okay. Okay.
If I just save it and if I just clear it and again try to run the crew you see this is the new path. So like this you can modify the path. I I just want to say that you can modify the path. Now if I say list all it is not yet there. Why? Because till now we have not created any um emitting. So what I'm going to do is now I'm going to uh kick off my crew with this input and let's see what we get.
Okay, so let's just clear it. Cle I run knowledge retrieval started. Uh this is the additional information that it got. Username is Axit. He's 24 years old and lives in Bangalore. Right. And uh knowledge retrieval completed. And this is the final uh output. So final output is hello Axit. I'm delighted to assist you. Based on the information you have provided, you are 24 year old 24 year old
residing in the vibrant city of Bangalore. So you see now the context is set for the agent for the crew and now it knows about me like this. What I'm going to do is there is one more way of providing knowledge to your crew. U I'll go back to docs and I'm going to provide I'm going to provide a PDF. Okay, let's go and provide a PDF knowledge source. So, I'll copy this PDF source and just below the
string source, I'm going to put it over here. And over here, we have already kept the story book PDF which has this 100 selected stories titles, just the titles, not the stories. So, just put storybook PDF and it should be good. So I'm going to clear it and let's try to run it again. Clear run. Yes, it should be retrieved. And yes, it got the information from the PDF and it also got my previous
information because string and PDF both the sources we have provided. And then I can see the final output based on information provided. The documents contain selection of 15 short stories by Henry. And here are the stories. Okay. So that's how it works. Now if you go back to um terminal and say ls- a I see the knowledge folder. I can go inside this knowledge folder and I can see what is there
inside this knowledge folder. So basically it is containing chroma file and the embedded documents. Okay. So I hope you like this video. All rest of the things you can explore on your own. Explore the embedder right. Explore the various knowledge sources. And that's it. And it is super simple, right? So I hope you enjoyed this video. Till the next video, keep coding, keep inviting.

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: e3xP_lAjktI
Language: en
Source: auto-generated
Saved At: 2025-08-26T05:31:45.995272
This is the ultimate beginner's guide to crew AAI automations. And it's fitting because I'm sure your news feeds have been flooded with GPT5, which means that we are also going to be using GPT5 with our automation. And we're going to go ahead and get started with what we're creating today. Now, when we begin the career flow, we always have an entry point. So, this is the start of the flow, and
that's where we're going to ask a user a topic that we want to discuss and then the audience level, whether it's going to be beginner, intermediate, or advanced. And the reason is because we're going to be building a comprehensive guide on whatever the topic is and whatever they choose to speak about. So the first step is we're going to validate the input. So the topic and whatever if it should be
a beginner or an advanced guide. And then based on that we're going to do some web research using firecrawl to retrieve certain information about that. Then we're going to go to step three pass all that in. We're going to create the guide outline. Then this is going to be done through a simple LLM call. So I'll show you how to do that. You don't always need a crew or you don't need to build out a
lot of things. This can just be a simple call to an LLM. Then we're going to take all of the guide outlines. We're going to write and compile them together using a crew. So, we're going to create a crew and they're going to work together to actually create the guide and then we're going to save that and view the output. And then over here, you see have the state management. That's because
throughout all of the steps with a crew AI flow, they handle the state of anything. So, we're going to be saving a lot of information throughout the duration of this flow. And with that said, we're going to begin with step one, and that's installing Crew AI and creating our flow. So, in order to install it, we're just going to copy and paste this. So, we're going to say UV tool install crew AI.
What this is going to do is this is I already have installed, but this is now going to allow us to create the crew from anywhere when we create a new project. Okay. So now what I can do is I can say crew AI. This is now a command that we had that we can use on our computer. So, crew AI create and then flow. And then we can name this whatever we want. We can say guide crew. Okay, cuz we're going to
be creating a guide. So whenever I do this, it just takes a minute. You can see as you're going to see here, that's going to create a full project for us. Okay, so it created it. It did it successfully. So over here on the lefth hand side, the guide crew, we have our source folder with a standard poem crew. We have our test and we have our main file that I'm about to go over that has our state
management and our flow. Now the first thing I want you to do is come over to this one of the files is pipro.toml. Okay, in the dependencies here, we need to add one more cuz we're going to be using firecrawl. I want you to type in here firecrawl- py. Okay, now we don't have to do this just yet, but whenever we get there, this will need to go ahead and install this for us. Okay, now going on to
step two. We need to get our open AI key, and we're going to go ahead and run the default crew flow just so you can see how it works. In the env file here, where we have the open AI key, you're just going to go ahead come in here and paste your API key. Okay, now I am inside of the guide crew. So I'm just going to go ahead and say crew aai install. This is going to create the dependencies based
off of this pi project.l file. It's creating thev env. And it's already done. You can see that right up here the virtual environment. So then we just go ahead and run this. So because it's a flow, we're going to say crewi flow kickoff. Okay. And then this is going to go ahead and run the whole flow and we're just going to see what we the basic poem crew or the poem flow with state management
working. Okay, this was very simple but we the flow finished for the poem flow. You can see there were three total steps here that it went through in the automation to create it. Now we're going to get ready to modify this for our guide outline but we need to know just a couple things first. So this is on step three understanding the annotations. So here we have in the poem flow you can see we
have a place where we want to start and then we have these listeners. These are all just Python functions and then we use AI as part of that but we can denote where we started by the at start and then we just have this Python function function to generate a sentence count. So this generates a random sentence count but the important thing here you see it says self.state sentence count. Well you see
up here we have a class called poem state and it has a sentence count. This means that whatever the this random number is between 1 and five, it's going to save it to this variable up here and during the whole duration of the flow, we can use this sentence count. Okay, so that's the first step is listening for whenever this Python function generate sentence count is finished. Then we're going to
run this. And so what we have in here is a poem crew of agents. So if I were to come in here, you can see that we have a poem writer agent and then a single task called write poem. And then they have their own background stories and everything that they need to execute in order to make this task work. Then when they're done, it'll say poem generated. It's going to save self.state.poem equals the
result from that crew. So up here, the poem property here for that state, it's going to save it here. So self.state.poem, this will have the actual poem that it created. And then finally, we're going to save that poem because we have this at listen that's listening for when the generate the generate poem function is complete. And then it writes that. And then it's going to write that here poem.ext
just like it did. And then here's the actual poem if we wanted to look at it. All right. So now we're going to be getting on the next part. We're going to be modifying this heavily for our guide outline. We're not going to code everything because this would be a much longer video if I coded everything out and explained it. That's reserved for something else. So I'm going to have some code already
pasted here. We're going to understand what they are step by step. All right. Now, we're moving on to step four and this is understanding our guide creator flow. Okay. So, we have a guide creation now that we had created and this is all the code that you're going to be using. But let's go over what this is. So, what do we modify? Well, first off, we have a different state, right? Does the name
doesn't matter. What matters is the name that you put in here. So, where it says class guide creator flow. We just want to change that state here. And then I have multiple properties inside of this state. Now I have some in here that I have importing from a models. So I have a guides py. Here are what we're going to be saving. Right? So I have a guide outline that has a title, introduction, the
target audience, sections, and a conclusion. And then the sections, each section is going to have a title and description for because we're going to have multiple sections. And then here I'm saving everything we do from our web research. Okay? So all of that is going to be saved throughout the flow into the state. So the first thing is we are going to be setting all the user inputs. So before this
we're going to ask the user what topic you want to talk about for instance GPT5 and all the use cases you can get from that and do you want this to be a beginner intermediate or advanced guide on that. Then after that's done we're going to perform web research and this is going to be using firecrawl. Now just quickly I'll have a video at the end or in the description where I have a full firecrawl
course. It's almost an hour long to help you understand everything you need to know and all the code is given to you in a repository about firecrawl. But what this code does is we create the firecrawl application and then we say search based on the topic. So we already are going to be saving that topic as state and then we want to know about whatever that topic is from the last week. Then we want
to return get the markdown and the links from that and then I'm just going to be saving that all of that information into the web search state. So back up here, web research state. We're going to be saving all information here to be used for the guide outline. Okay. Then the next part that we had in our steps was we want to now create the guide outline. Okay. So now we're going to create the
structured guideline. And how we're going to do this is it's going to be through an LLM call. So we say llm equals and then we're going to give the model and then how we want it returned back to us. We want it in a certain state called guide outline in so we want specific things uh whenever it creates all this we want to be in a specific structured output. That's what we're doing here with the
guide outline. And again we're using the brand new model. We're we're going to see how it works. And then with this we just need the messages. So this basically means what the system and the user prompts right? This is basically what we're giving it. Then we can just say response equals llm call. Pass in those messages and then we're just going to get that response back. We're going to create a
directory and we're just going to have that out out guide outline JSON file there. So now we have the whole guide outline and the crew will take that information and create it for us. And again we're saving that guide outline into the state called guide outline which is at the top here. Guide outline. Now we're moving on to step four of the flow. We at the inputs we did the web research. We
created the guide outline. Now we need to write and compile the guide. So this means for each section that we had created, now we need to go in there. For each section, we're going to have a crew of agents fill out that section. But first, we need to create the crew. Now, I already have it created, but let me show you how to do this. So, I'm going to bring back up the terminal. How you do that is
you're going to say crew AI flow add crew. And I already have a content crew. So, let's just call this example crew. And what I want you to notice over here on the lefth hand side, we have a content crew and a poem crew. So whenever I press enter, it's going to create another folder with the structure of everything we need for that crew. And it tells you right here. So here I have the example
crew, the example crew uh py file and I had the configuration. So I have all the agents. I have the role, the goal, and the backstory for each agent and the task that came that came with it with the configuration as well and for which agent is going to be taking care of that task. Now, if you're feeling a little bit overwhelmed, I have a full 2-hour course on Koreai that you can watch. I'll have
that in the description below. If you have any comments or any suggestions about this, please leave them in the comments as well. But I have a full course for you if you need help. Okay, so we had created the crew and then I modified it. So if we go into the crew, we don't need to spend much time here, but you can see here we have a content writer and then a content reviewer. So the content writer
has the right section task and then the reviewer has a review section task and we modified the config configuration for each agent in their task and this is just to make sure that everything that we're doing is like structured and we want them to take all the information but then we want to give them some parameters on how we want these want each section of these guides done. Okay. And then for
each section, it's going to save it into the state. It's going to basically put them all together and it's going to then create this guide outline. So this complete guide, which means for step number five, we need to actually run this as an example and go through what happened. So we have this kickoff function that we did in the terminal. This is the kickoff function that is going to execute.
Okay, so here just some Python code that we ask the person what topic do they want and we're in this while loop so that you have to choose either beginner, intermediate or advanced like who is your target audience for this. Then we have these inputs for the topic and audience level and then we say guide creatorflow.kickoff. So we give them these inputs. Now a quick tip, this is actually a more
advanced way of doing this but I just wanted it. it made a little more sense and the terminal doesn't look look right if it's not done this way. But if we come back up here, whenever we start the flow and we have those because they were as inputs, it's automatically going to add those here as a topic and audience level. Let's go ahead and run this again. It's just say it's just crew AI flow
kickoff. Okay. So, what topic would you like to do for us? How about we just do use cases for GPT5 and let's do beginner. Okay. So this basically means that it now it's going to do all the web research about GPT5 use cases. So here the topic we have the uh the audience level. So now it already performed the web research. See it completed that right here. So that's already done. That was very
quick. It is really quick. Fire makes that uh does that really well. So then the next task is it wants to create the guide outline. So then this is going to take a little bit longer. Okay. So it created the guide outline and in the output you know it created it was going to create a JSON file for us. So here here are some you can see the title and it created the title and descriptions. So then
basically for each of these sections we're going to have that content crew come into each of these and create and fill out and create that actual section for us as the guide. And that's what it's doing right now. So we're going to uh execute with the crew the running the write and compile guide. So we can see now we have a crew we have the educational content writer that is the name of the agent
and then it's going to write a comprehensive section on the first case which was writing and content creation. So it's going to come in here. It's going to do it for all of the sections. Okay, so it take it took a little bit longer, so I just went ahead and let it run. But basically, it went through like six different sections. I had the content writer and then the review reviewer for each of
those. And then finally down here at the end, it completed. So the crew execution completed for the last top for the last section and then the flow finally finished. So then the write and compile guide was done and all the steps were complete. Now we need to see what this looks like. So over here in the output on lefth hand side we have the complete guide.mmarkdown and this doesn't look like much
but so what we can do is there's an extension I have where you can preview the markdown in a better in a better way. So let me bring this over here bring that away. Okay so then this is kind of what the markdown would look like. It has the different sections for GPT5 uh things like different use cases plus it's going over improvements for it as well. But this is a relatively big document, but I've
done this for like how to create fast API, how to create NATN like or looking up best NATN use cases, how to create them or the best practices. Like you can have guides for anything. Here's about having agentic task and automation. Let GPT5 do more for you. And then what I've done is whenever you have like coding things on here like what you can do for coding, this guide just really helps out and
it can it can just be really amazing to have something create this for you. So now you can have automation if you need a guide for a certain topic whether it's you're teaching it, you know, potentially selling it or maybe as a cheat sheet for something that you're making, whatever that may be. But GBT5 did a very good job. I already kind of reviewed this and this is this is pretty good. You'll
have this in GitHub whenever you go to download this. I have a link for the all the code in my GitHub. It'll be under AI here. I have already have 850 stars on this. This has a lot this right here. This AI one has a lot of things, a lot of projects already in here for you. And just as a heads up, this will be in my tutorial section for you already ready to go with the exact instructions that you
need to set this up as well. So look guys, thank you for watching AI automation. And if you're creating AI agents as part of those things, it takes a little time. Don't worry about how it gets there. The tools are agnostic, right? To solve the problem is you want to have the solution. So that solution doesn't matter what tool you use to get there. I am a developer. So I like programming and I
personally think you can scale and do a lot of different things other than just actually creating automation. There are other things in the background you need to worry about and you can do more with that with coding. But whatever it however you're doing it, you can get it done. and just worry about what problem that you want to solve. Again, join my school community. I have a free trial right now
that you can use to join. I'm here to help everybody. And if you need something done for you, have a discovery call with me in the description below and I will get it done for you. Thank you for watching. Here are some more videos for you to watch. In the meantime, I will see you next video.

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: 8pnkEdIHEmk
Language: en
Source: auto-generated
Saved At: 2025-08-26T05:31:47.944759
Start. Start again. Okay. Hey, I'm Luke and I am one of the developers of Agent Up and going to be Hey. Hi. I'm Luke. I'm one of the AgentUp developers. I'm going to be showing you the integration of Crew AI and Agent Up. Uh Agent Up. If you're new to the project, which most of you will be, it's in active development. And Agent Up is the operating system for agents. So you're able to very quickly
boot up an agent and then it's configurationdriven in very much the same way as a Unix type system. Everything is decorative within configuration files and that determines your runtime. So it's very modular but beyond that it's actually very very extensible. We have this plug-in system but the nice thing about the plug-in system is you can have your own custom code which can do whatever you want.
Anything that you can program you can have there. keep it in its own repository and then it can be revision pinned to the agent up core. So effectively it acts as a dependency but it gets full unfettered access to all of agent ups security middleware caching state management. Agent up is part of the A2A specification. So it's very good at speaking with other agents. Uh I've been going on a little
bit longer than I wanted to. So let's look at the demo. So we have a couple of agents. I'm going to start those up. One of them is a weather agent and uh nothing in particularly flash. It is a uh it gets the weather using an MCP server. Uh the second one is a agent which is uh using Brave. It's using the Brave search tool. And for this one I'm going to do things slightly different. You're going to
see me install a plugin. So we have our own registry. And you'll notice I'm using pip. So the nice thing about this is plugins can be revision controlled within PI project or requirements.ext or whatever it is you like to use. So your agent can have dependencies. MCP uh tools and so forth can be dependencies. So you could use something that the community's built or you could write something
yourself. So we will install that and then I will then run the agent up plug-in command. And you can see there's our brave search tool and something else you will notice is there is scopes. So all tools and all MCP servers are enforced at runtime to use certain scopes. So you will have a token system where for example OR2 or JWTJSON web tokens you would assign scopes to a user and then agent up
will then cryptographically check that token extract the toes the extract the toes extract the tokens and then only allow uh the user to uh get access to the tools and the capabilities of those tools that they've been granted. So that is now installed. So, we're going to start our server. I'm going to make sure I run this on a different port. So, we'll run that on 81. And then over here, I have a
a script. Okay. So, if we look at this, it's it's essentially all crew AI. Uh the only difference is there is this agent up tool which you inherit. And that allows you to then present agent up agents as tools in MCP. So, the crew AI orchestrator will connect to the AgentUp agent as a tool. Uh, but you will get all of the state persistence and the history and the security and all of the middleware
baked into agent up. So, you get a lot of extra bang for your buck there. So, we're going to run this and this is uh two agents. We've got a weather agent and an internet search brave agent. And the task is to get the weather for New York right at present. get any weather alerts and then do an internet search to look at what is the average weather in New York for this time of the year and then it
will compare the current weather to the average weather and then crew AI will summarize its findings. Okay, so let's run this and hopefully the we don't get the demo effect and so all looks good. So you can see straight away it's called uh the MCP weather server. This is just a demo MCP server that's uh that's that's batched in with agent up. You can install whichever ones you want. Uh it's now
it's got the alerts. So we should see it jump across to Brave search which it will do shortly. There we go. You can see Brave search is starting up. So that's performed a search. And then we can see the tool output has been returned. And what should happen now is crew AI will summarize its findings. So it will consider the current weather, what is the historical average weather and then we'll
summarize from there. So we're just waiting on OpenAI and Crew AI. So there you go. There you have it. So very very quick and simple to set up uh agents MCP service that you want, tools that you want, uh any any middleware that you want, you can you can get agents up and running very quickly and they can interact with crew AI as effectively tools. So I will leave it there and um any questions do
let me know and thank you for your time.

===== END TRANSCRIPT =====

===== BEGIN TRANSCRIPT =====
Video ID: O2gerCxEXvc
Language: en
Source: auto-generated
Saved At: 2025-08-26T05:31:49.787852
My goal today is to explain the difference between these three terms in a most simple language. When you ask a question to chat GPD as a result, it will generate new text. It can also generate uh images, videos and so on. So generative AI is nothing but an AI that can create new content either text, image or video based on patterns learned from existing data. At the heart of it there is large
language model and this model can be your GPT4 claude model Gina etc. It is trained on a huge volume of internet data okay it can be Wikipedia text Google books and so on and based on that it will be generating the answers. Now if you ask this question, what is the price of a flight ticket tomorrow? It won't be able to answer because it has a knowledge cutff date and this is a generative AI with
only LLM. But you might have noticed if you ask some questions to chat GPT you will see this searching the web text and it will do the web search and it will return you the latest information from internet. So in this LLM if you give an access to Xedia API or let's say make my trip or any other travel API then LLM is smart enough to call this API and fetch the latest price of a flight. Okay. So
this is getting little more intelligent than just simple LLM which is trained on some knowledge cutoff. Right. So LLM is like a brain and to that brain you are giving this access of a tool. Right? Let's say you are a human you have a brain but I give you a hammer and a screwdriver you will be able to do even more. So similarly for LLM these tools then there is another thing called knowledge. These
are like its hammers and screwdriver which will help it do even more. You can also ask book me a cheapest flight tomorrow from place A to B and using Xedia API it will first search different flights then it will decide the cheapest one and then it will book uh that flight. So here you are now performing actions. Previously you are asking questions simple Q&A but now it is actually taking action
for you. This is an AI agent. It is a program that takes input. It will think and it will act to complete a task. Okay. Agent will complete task. It's not just simple Q&A chatboard. It will complete a task using tools, memory and knowledge. And there is some kind of autonomy or independent decision making. So when we looked at previously see it decided which is the cheapest flight. So maybe it
found let's say five flights and it figured out okay this is the cheapest flight and then it booked it. So it is taking independent decision. Okay. So it is autonomous but at the same time the example that we looked at is very narrow and specific. Okay. I'm asking okay from place A to B book a flight tomorrow cheapest flight. So it's a simple task. It's not that complex. It doesn't involve u you
know multiple like step reasoning multi-step planning and so on. But now let's say you ask even a more complex question such as I want to travel to New Delhi in May. It is 7-day trip. Weather should be sunny on all the days. Flight budget is less than $1,600. No layover. Now this is the kind of question you will ask your travel agent right when you call it. Okay, these are my five criterias. Give
me the best flight. Well, apparently AI agents can do this. So it has access to Xedia for your travel needs. Now it needs to check weather also because you like sunny weather. So what you can do is provide an access to some weather API you know acue weather API whatever API and then it will first check the weather. Okay. So it will look at the month of May and find seven consecutive days where the
weather is sunny. For those days it will do a flight search, compare airlines, find the flight with a budget less than 1600. Okay. Not only that, it might go one step further and give you suggestions for hotel and airport taxi. Okay. So see I booked a flight and I also found you few good suggestions. So this is a flight booking AI agent. You see here it's a flight booking AI agent which is doing a
complex task than the simple AI agent. You can expand it further because when you travel across countries you might need visa. So maybe it can do even more complex things such as it can call another AI agent which is immigration AI agent and this agent is also powered by LLM obviously but it has access to let's say some uh immigration APIs it has access to your one drive where you have kept your
passport and your immigration records and now this immigration a agent right this green box will check your visa eligibility and and it will say hey you know what your visa has expired so even before you book a ticket you need to apply for a visa so this is even a complex system where there is not just one agent there are two agents right the first agent is flight booking second one is immigration
AI agent so the system as a whole if you think about the entire system it is doing multi-step reasoning it is not like okay go and book the flight ticket it knows that you need to check visa so it will call visa agent and check if the visa is there and if visa is there then it will do further steps. So it is doing multi-step reasoning multi-step planning and working on a complex goal autonomously.
Okay. Now there is some control you need to give uh uh you need to keep on this agents. You can't make them fully autonomous. You can't give them your bank password. So there is some level of control that needs to be given. So agentic AI is a system where one or more AI agents work autonomously often over long task complex task making decisions using tools and even other agents to reach a goal.
Okay. So as you can see as you evolve from simple generative AI system with only LLM to AI agent to agentic AI you are capable of performing even more and more complex task. With only LLM you get just Q&A with the knowledge cutff with AI agent you can get access to tools and memory and you can perform narrow simple task. With agentic AI you can have multiple agents. It's not absolutely required
that you need to have multiple agent. By the way, agentic AI can have single agent only. But other than agent, it has other components and it is able to handle multi-step goals with planning and coordination. Tool usage in genai is non. AI agent will use tools and agent also uses the tools and autonomous decision making is highest. When it comes to agentic AI, there are many tools available that
you can use to build agentic AI system. One of the tools is N8N. So I am showing you the workflow diagram in N8N. And here uh LLM will be part of it. Okay. So if you look at any uh agentic AI system, it will have generative AI as a core component of it. Okay. So this entire system is AI agent and one of the component is your Gemini LLM model which is generative AI. So generative is part of or a
component of agentic AI systems. There are many frameworks available to build agentic AI systems agnu and so on. And uh by the way whatever definitions we have discussed don't take them uh like too rigidly you know some people like no AI agent means this and agentic AI means this. My friend who is a creator of Agno framework defines these agentic system into five levels. Okay. So first level is
agent with tools and instruction. Level two is agents with knowledge and so on. So different people define it differently. As long as you understand this core fundamental which is agents are able to do uh some kind of autonomous action for narrow task. And when you move to agentic AI, your complexity increases and usually there are more than one agent. So generative AI to AI agent to agentic AI,
the complexity of the task that you can perform increases and it becomes more and more sophisticated. Now folks, I have this langraph tutorial where I have explained how to build AI agents using this popular framework. So just watch it out. I have given examples of how do you build a chatbot with tools and memory human in the loop etc. If you want to build build fully agentic AI system such as
let's say you want to onboard an employee who is joining the organization then in our AI boot camp we have this complete project where you just say okay onboard this new employee and what it will do is it will add the employee to HRMS system it will send welcome email to employees it will notify the manager and so on. So here we used clot desktop as a front end and as a back end we have built an
MCP server. Okay. So that's part of our boot camps project. I hope uh this particular video gave you some understanding on these three different concepts. If you have any questions post in the comment box below. If you like this video give it a thumbs up and share it with your friends.

===== END TRANSCRIPT =====

